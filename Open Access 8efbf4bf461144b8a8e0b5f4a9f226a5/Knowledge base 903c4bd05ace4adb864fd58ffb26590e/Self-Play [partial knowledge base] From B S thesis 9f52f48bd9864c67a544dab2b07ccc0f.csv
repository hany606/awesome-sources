Importance,Title,Link,Type,Status,Tags/Keywords,Notes,Conference,Year,*Evaluation of performance,*Opponent selection + Training,Intervention,Results,Appraisal,Possible shortcomings,Possible developments / Future / To improve / Extension
10,[AlphaStar] Grandmaster level in StarCraft II using multi-agent reinforcement learning,,Paper,Done,,"Introduces a lot of details about SP and FSP, explains the RPP",,,,,,,,,
10,A Comparison of Self-Play Algorithms Under a Generalized Framework,https://arxiv.org/abs/2006.04471,Paper,Done,selfplay,"Introduce formalization for self-play and much more, introduce good survey for the available methods, introduce good intutions and thoughts",,,,,,,,,
10,[DeepMind - CTF] Human-level performance in 3D multiplayer games with population-based reinforcement learning,,Paper,Done,,"Interesting work
Explains and removes a lot of assumptions made previously in others work → independent agents, local information, only from pixels

CTF → Capture The Flag

Some interesting things about game theoretical solutions

Cool work about the sparse reward and how they solved with meta learning somehow as far as I understand",,,,,,,,,
10,"[ICLR 2019 Rejected, Abbeel and Levine] Hierarchical Deep Reinforcement Learning Agent with Counter Self-play on Competitive Games",,Paper,Done,,"Gives really good literature review and explains a lot of stuff.

Uses hierarchical and ensemble methods, uses Counter SP as well",,,,,,,,,
10,[DeepMind] Malthusian Reinforcement Learning,,Paper,Read it again!,,"To be honest did not get it.

It seems that it gets results better than SP",,,,,,,,,
9,Emergent Tool Use From Multi-Agent Autocurricula [OpenAI: Hide-seek],https://openai.com/blog/emergent-tool-use/,Paper,Done,"Behavior, Learning-based, selfplay",,,,"They have used transfer as a metric
And something called intrinsic motivation (Did not undertand this part fully)",Nothing was mentioned about how the training works,,,,,
9,[Open AI] Dota 2 with Large Scale Deep Reinforcement Learning,,Paper,Done,selfplay,"This paper is really good. It is about TrueSkill, architechture and interesting thing about surgeries for the training models.",,,,,,,,,
9,[Bansal et al] Emergent Complexity via Multi-Agent Competition,https://openreview.net/forum?id=Sy0GnUxCb,,,,,,,,,,,,,
8,"[Google paper + Deepmind] From Motor Control to Team Play in
Simulated Humanoid Football",https://arxiv.org/pdf/2105.12196.pdf,Paper,"Done, Read it again!","Behavior, MARL, NvM, selfplay","It does not cover a lot on self-play concept

Their method seems to have population of agents and then train using self-play then mutate and get the offspring from the results

Outer (Sefl-play) and inner learning loop",,,"Elo-score

Evaluate against benchmark, human, specific evaluation agents

Counterfactual Policy Divergence: We use the counterfactual policy divergence (CPD) technique (47) to measure the extent to which the behaviour of a player is influenced by different objectss in the football scene (ball, teammate, opponent). We measure the KL-divergence induced in the policy by repositioning (or changing the velocity) of a single object",Select the opponents randomly,,,,,
8,[ICLR rejected] Efficient Competitive Self-Play Policy Optimization,https://openreview.net/forum?id=99M-4QlinPr,"Code, Preprint",Done,,"It was submitted to ICLR 2021 but was rejected
Some theoretical proof and some results for their new algorithm",ICLR,2021,"They are using Elo score, and they showed the mean/average reward (Win-rate) (Did not understand this part correcty). 

They are making evaluation between models from different algorithms (Pairwise competition) among all the checkpoints. Each competition/evaluation round between two opponents has multiple of matches","At the begining we have a population of e.g. 8 members, they run evaluation against all these 8 members, then they select the best opponent in terms of this evaluation and train against it

The problem that it is time consuming I believe with more populations not enough generalization, might not be good for hard tasks (continous action space, NvM, complicated tasks) (as they did not try with hard tasks only robot sumo)",Some theoretical proof and some results for their new algorithm,,,,
7,Neural Tree Expansion for Multi-Robot Planning in Non-Cooperative Environments,"https://www.youtube.com/watch?v=tkmTYUWnAOw
With good explanation for the paper",,,Learning-based,"They are claiming that they beat the SoTA of optimal control. They have adapted the method of AlphaZero and used it ",,,Nothing further,Not something that is clear,,,,,
7,[DeepMind] Open-Ended Learning Leads to Generally Capable Agents,,Paper,Done,MARL,"Cool work but nothing too much about self-play, it is more too the environment and the training as whole. Furthermore, they discussed an important direction for marl about open-ended environments and the generalization for the tasks",,2021,,,,,,,
7,Fictitious Self-Play in Extensive-Form Games,,Paper,Done,"Game theory, selfplay","Some interesting information about fictitious play, game theory and self-play and nash-equilbruim

",,,,,,,,,
7,An Introduction of mini-AlphaStar,,"Code, Paper",Done,,Explains about alpha-star but not important paper,,,,,,,,,
7,Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm [DeepMind],http://arxiv.org/abs/1712.01815,Paper,Done,"Learning-based, selfplay",,,,Using Elo rating and winrate,They are training against the best player,,,,,
6,Deep Reinforcement Learning from Self-Play in Imperfect-Information Games,,Paper,Done,"Game theory, selfplay",Has some info about game theory solutions and self-play,,,,,,,,,
6,TLeague: A Framework for Competitive Self-Play based Distributed Multi-Agent Reinforcement Learning,,,,,"Presents open-source work for a framework for self-play for large-scale training

Really interesting work",,,,,,,,,
6,Mastering the game of Go with deep neural networks and tree search,,Paper,Done,,"Nothing new about self-play, however the whole problem and its solution is awesome one of SoTA indeed",,,,,,,,,
5,Control strategies for multiplayer target-attacker-defender differential games with double integrator dynamics,http://ieeexplore.ieee.org/document/8263864/,Paper,Done,Non-learning,"They are using non-learning based methods → optimal control and optimzation methods with some assumptions like the information that the agents posses and the dynamic model of the agents

According to “Neural Tree Expansion for Multi-Robot Planning in Non-Cooperative Environments” This paper is the SoTA for such games. ",,,,,,,,,
5,TrueSkill 2: An improved Bayesian skill rating system,,"Paper, Report",Done,Match-making,"Interesting paper, proviedes good intiution and data about how the match-making is done in games",,,,,,,,,
5,Adversarial Policies: Attacking Deep Reinforcement Learning,"https://github.com/HumanCompatibleAI/adversarial-policies

https://adversarialpolicies.github.io/",Paper,Done,,"Really an interesting paper about adversarial agents for self-play multi-agent RL

These agents are exploiting the opponents by adversarial stupid strategies that makes it unable to finish
",,,,,,,,,
4,Brown's original fictitious play,,Paper,"Done, Read it again!",Game theory,About Fictitious play with some interesting details but nothing useful for my current knowledge,,,,,,,,,
3,AWESOME: A General Multiagent Learning Algorithm that Converges in Self-Play and Learns a Best Response against Stationary Opponents (2006),http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.2398,Paper,Done,,"Only repeated games. and some other assumptions on known the game dynamics and payoff

It has a lot of assumptions, that in our case is not hold for our case: “The agents can compute their own nash equil.”",,,,,,,,,
3,Near-Optimal Reinforcement Learning with Self-Play,,Paper,"Continue Reading, Read it again!",,"It has some good math and formlations but I hardly understood something.

It is more analytic paper not implemented → Theory",,,,,,,,,
3,Arena: A General Evaluation Platform and Building Toolkit for Multi-Agent Intelligence,,Paper,Done,,Interesting environments,,,,,,,,,
3,Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot,,Paper,Done,MARL,"Not important for self-play, but includes a list of papers for self-play works",,,,,,,,,
3,"[Application, Facebook AI] Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play",,Paper,Done,"RL, selfplay","Interesting paper for using self-play in order to create a hard curriculum learning for the single agent to generalize and explore the environment faster and solves the problem of the sparse reward

Related papers: HER, CER, Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space",,,,,,,,,
3,[Application of SP for Single Agent]  Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space,,Paper,Done,"Algorithm, RL, selfplay","Interesting paper
It uses self-play as a method to make single-agent RL trains better. Good idea to test and check the performance.

Treat single-agent RL as a multi-agent self-play (Imagine that you are competing with someone) Think about HER, CER (COMPETITIVE EXPERIENCE REPLAY) as well
",,,,,,,,,
,[Prof. Taylor paper] A Survey and Critique of Multiagent Deep Reinforcement Learning,https://arxiv.org/abs/1810.05587,Survey,Done,MARL,They mentioned small part on self-play,,,,,,,,,
,"[Facebook] Control Strategies for Physically Simulated Characters Performing
Two-player Competitive Sports",https://research.fb.com/publications/control-strategies-for-physically-simulated-characters-performing-two-player-competitive-sports/,Paper,Continue Reading,"1v1, selfplay","Used more for the graphics industry, no focus on self-play method, but on the output of the work itself",,,,,,,,,
,[Albrecht + Stone] Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems,https://arxiv.org/abs/1709.08071,Survey,Done,Modeling,It is about modeling the other agents. It is not very really related to my thesis but has some cool ideas and a great survey for agents modeling,,,,,,,,,
,,,,,,,,,,,,,,,
,[Math paper] Provable Self-Play Algorithms for Competitive Reinforcement Learning,https://proceedings.mlr.press/v119/bai20a.html,Paper,"Done, Read it again!","Math, selfplay","It is a very hard paper, very theoretical paper. But a really interesting paper",,,,,,,,,
,[Prof. Albrecht paper] Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning,https://arxiv.org/abs/1906.04737,"Paper, Survey",Done,MARL,They mentioned small part on self-play,,,,,,,,,
,Survey of Self-Play in Reinforcement Learning,https://arxiv.org/pdf/2107.02850.pdf,"Paper, Survey","Done, Read it again!","Game theory, selfplay","Surprisingly, this paper discussed more the game theory point of view not from RL point of view at all",,,,,,,,,